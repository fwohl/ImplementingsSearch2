{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "xrerBaVpgdG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgmcvfAAGAz2",
        "outputId": "5a3caa42-ab25-46a2-d804-6e69810e5e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install iv2py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZpelSrWhOBt",
        "outputId": "2108c8c1-d8a0-405d-d8c7-55f82921d481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting iv2py\n",
            "  Downloading iv2py-0.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (496 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/496.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/496.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m491.5/496.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.9/496.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: iv2py\n",
            "Successfully installed iv2py-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl1OxNBVnBkg",
        "outputId": "24736138-fc71-49a4-b6fe-729ccec59ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.23.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FM Index"
      ],
      "metadata": {
        "id": "em-F1MNEfAM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import iv2py as iv\n",
        "import os\n",
        "\n",
        "# load index or create an index\n",
        "if os.path.exists(\"file.fmindex\"):\n",
        "    # load fm index from disk\n",
        "    index = iv.fmindex(path=\"file.fmindex\")\n",
        "else:\n",
        "    # load fasta file - normalize sequences (e.g.: make everything capital letters, check for invalid characters)\n",
        "    reference = [iv.normalize(rec.seq) for rec in iv.fasta.reader('/content/drive/MyDrive/data/hg38_partial.fasta')]\n",
        "\n",
        "    # build fmindex\n",
        "    index = iv.fmindex(reference=reference, samplingRate=16)\n",
        "\n",
        "    index.save(\"file.fmindex\")"
      ],
      "metadata": {
        "id": "53bXjo_sxMWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the file imports ok\n",
        "import iv2py as iv\n",
        "\n",
        "fasta_file_path = '/content/drive/MyDrive/data/hg38_partial.fasta'\n",
        "\n",
        "for record in iv.fasta.reader(file=fasta_file_path):\n",
        "    print(\"ID:\", record.id)\n",
        "    print(\"First 10 letters of Sequence:\", record.seq[:10])\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fldsm2oQ0HXf",
        "outputId": "62d85ddd-4895-465c-a7bb-54f8355f7cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: NC_000001.11 Homo sapiens chromosome 1, GRCh38 Primary Assembly\n",
            "First 10 letters of Sequence: TGCTCTGACC\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1'000"
      ],
      "metadata": {
        "id": "KEYH4DfRfjdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "\n",
        "# List the Illumina files\n",
        "illumina_files = [\n",
        "    'illumina_reads_100.fasta',\n",
        "    'illumina_reads_40.fasta',\n",
        "    'illumina_reads_60.fasta',\n",
        "    'illumina_reads_80.fasta'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file\n",
        "total_time_per_file = {file: 0 for file in illumina_files}\n",
        "\n",
        "for illumina_file in illumina_files:\n",
        "    for _ in range(num_iterations):\n",
        "        # Load Illumina file\n",
        "        illumina_file_path = '/content/drive/MyDrive/data/' + illumina_file\n",
        "        for record in iv.fasta.reader(file=illumina_file_path):\n",
        "            # Consider the first 1,000 characters in the current sequence\n",
        "            reference_text_chunk = record.seq[:1000]\n",
        "\n",
        "            # Measure the time for searching in the FMIndex\n",
        "            start_time = time.time()\n",
        "            res = index.search(reference_text_chunk)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Accumulate the total time per file\n",
        "            total_time_per_file[illumina_file] += end_time - start_time\n",
        "\n",
        "# Calculate the average time per file\n",
        "average_time_per_file = {file: total_time / num_iterations for file, total_time in total_time_per_file.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, average_time in average_time_per_file.items():\n",
        "    print(f\"Average time for {num_iterations} iterations in {file}: {average_time:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1l8DrVKAufX",
        "outputId": "2c936384-a13f-4fd1-f746-c0cabf7aea6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in illumina_reads_100.fasta: 0.929409 seconds\n",
            "Average time for 100 iterations in illumina_reads_40.fasta: 0.669361 seconds\n",
            "Average time for 100 iterations in illumina_reads_60.fasta: 0.727284 seconds\n",
            "Average time for 100 iterations in illumina_reads_80.fasta: 0.838563 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10'000"
      ],
      "metadata": {
        "id": "Hana5SOtftRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "\n",
        "# Assume you have your reference text loaded in the 'index' variable\n",
        "\n",
        "# List the Illumina files\n",
        "illumina_files = [\n",
        "    'illumina_reads_100.fasta',\n",
        "    'illumina_reads_40.fasta',\n",
        "    'illumina_reads_60.fasta',\n",
        "    'illumina_reads_80.fasta'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file\n",
        "total_time_per_file = {file: 0 for file in illumina_files}\n",
        "\n",
        "for illumina_file in illumina_files:\n",
        "    for _ in range(num_iterations):\n",
        "        # Load Illumina file\n",
        "        illumina_file_path = '/content/drive/MyDrive/data/' + illumina_file\n",
        "        for record in iv.fasta.reader(file=illumina_file_path):\n",
        "            # Consider the first 10,000 characters in the current sequence\n",
        "            reference_text_chunk = record.seq[:10000]\n",
        "\n",
        "            # Measure the time for searching in the FMIndex\n",
        "            start_time = time.time()\n",
        "            res = index.search(reference_text_chunk)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Accumulate the total time per file\n",
        "            total_time_per_file[illumina_file] += end_time - start_time\n",
        "\n",
        "# Calculate the average time per file\n",
        "average_time_per_file = {file: total_time / num_iterations for file, total_time in total_time_per_file.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, average_time in average_time_per_file.items():\n",
        "    print(f\"Average time for {num_iterations} iterations in {file}: {average_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yRPRBhuGErN",
        "outputId": "fe14aa72-d734-4a24-bb79-3811ccab46e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in illumina_reads_100.fasta: 0.939037 seconds\n",
            "Average time for 100 iterations in illumina_reads_40.fasta: 0.658318 seconds\n",
            "Average time for 100 iterations in illumina_reads_60.fasta: 0.712422 seconds\n",
            "Average time for 100 iterations in illumina_reads_80.fasta: 0.835486 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 100'000"
      ],
      "metadata": {
        "id": "eLnufHCdf4mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "\n",
        "# List the Illumina files\n",
        "illumina_files = [\n",
        "    'illumina_reads_100.fasta',\n",
        "    'illumina_reads_40.fasta',\n",
        "    'illumina_reads_60.fasta',\n",
        "    'illumina_reads_80.fasta'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file\n",
        "total_time_per_file = {file: 0 for file in illumina_files}\n",
        "\n",
        "for illumina_file in illumina_files:\n",
        "    for _ in range(num_iterations):\n",
        "        # Load Illumina file\n",
        "        illumina_file_path = '/content/drive/MyDrive/data/' + illumina_file\n",
        "        for record in iv.fasta.reader(file=illumina_file_path):\n",
        "            # Consider the first 100,000 characters in the current sequence\n",
        "            reference_text_chunk = record.seq[:100000]\n",
        "\n",
        "            # Measure the time for searching in the FMIndex\n",
        "            start_time = time.time()\n",
        "            res = index.search(reference_text_chunk)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Accumulate the total time per file\n",
        "            total_time_per_file[illumina_file] += end_time - start_time\n",
        "\n",
        "# Calculate the average time per file\n",
        "average_time_per_file = {file: total_time / num_iterations for file, total_time in total_time_per_file.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, average_time in average_time_per_file.items():\n",
        "    print(f\"Average time for {num_iterations} iterations in {file}: {average_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOdTiapbILRm",
        "outputId": "e92d9fbb-25ae-4133-dd16-5d5784a1ab79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in illumina_reads_100.fasta: 0.974272 seconds\n",
            "Average time for 100 iterations in illumina_reads_40.fasta: 0.664467 seconds\n",
            "Average time for 100 iterations in illumina_reads_60.fasta: 0.700332 seconds\n",
            "Average time for 100 iterations in illumina_reads_80.fasta: 0.820276 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1'000'000"
      ],
      "metadata": {
        "id": "vJFygM5VgBIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "\n",
        "# Assume you have your reference text loaded in the 'index' variable\n",
        "\n",
        "# List the Illumina files\n",
        "illumina_files = [\n",
        "    'illumina_reads_100.fasta',\n",
        "    'illumina_reads_40.fasta',\n",
        "    'illumina_reads_60.fasta',\n",
        "    'illumina_reads_80.fasta'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file\n",
        "total_time_per_file = {file: 0 for file in illumina_files}\n",
        "\n",
        "for illumina_file in illumina_files:\n",
        "    for _ in range(num_iterations):\n",
        "        # Load Illumina file\n",
        "        illumina_file_path = '/content/drive/MyDrive/data/' + illumina_file\n",
        "        for record in iv.fasta.reader(file=illumina_file_path):\n",
        "            # Consider the first 1,000,000 characters in the current sequence\n",
        "            reference_text_chunk = record.seq[:1000000]\n",
        "\n",
        "            # Measure the time for searching in the FMIndex\n",
        "            start_time = time.time()\n",
        "            res = index.search(reference_text_chunk)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Accumulate the total time per file\n",
        "            total_time_per_file[illumina_file] += end_time - start_time\n",
        "\n",
        "# Calculate the average time per file\n",
        "average_time_per_file = {file: total_time / num_iterations for file, total_time in total_time_per_file.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, average_time in average_time_per_file.items():\n",
        "    print(f\"Average time for {num_iterations} iterations in {file}: {average_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGLqHyXedwe5",
        "outputId": "9c154e02-9f13-4e3b-e8e8-568202ffd892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in illumina_reads_100.fasta: 0.904364 seconds\n",
            "Average time for 100 iterations in illumina_reads_40.fasta: 0.647883 seconds\n",
            "Average time for 100 iterations in illumina_reads_60.fasta: 0.747147 seconds\n",
            "Average time for 100 iterations in illumina_reads_80.fasta: 0.832899 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human Genome Files"
      ],
      "metadata": {
        "id": "R4U8i7XMOl3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1'000"
      ],
      "metadata": {
        "id": "P3Z-BZ9OhUdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "\n",
        "# List the Human Genom files\n",
        "genom_files = [\n",
        "    'GCA_000001405.15_GRCh38_genomic.fna',\n",
        "    'GCF_000001405.26_GRCh38_genomic.fna'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file\n",
        "total_time_per_file = {file: 0 for file in genom_files}\n",
        "\n",
        "for genom_file in genom_files:\n",
        "    for _ in range(num_iterations):\n",
        "        # Load Genom file\n",
        "        genom_file_path = '/content/drive/MyDrive/data/' + genom_file\n",
        "        for record in iv.fasta.reader(file=genom_file_path):\n",
        "            # Consider the first 1,000 characters in the current sequence\n",
        "            reference_text_chunk = record.seq[:1000]\n",
        "\n",
        "            # Measure the time for searching in the FMIndex\n",
        "            start_time = time.time()\n",
        "            res = index.search(reference_text_chunk)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Accumulate the total time per file\n",
        "            total_time_per_file[genom_file] += end_time - start_time\n",
        "\n",
        "# Calculate the average time per file\n",
        "average_time_per_file = {file: total_time / num_iterations for file, total_time in total_time_per_file.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, average_time in average_time_per_file.items():\n",
        "    print(f\"Average time for {num_iterations} iterations in {file}: {average_time:.6f} seconds\")"
      ],
      "metadata": {
        "id": "wkAHBqTH88Xx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84089bd1-dd28-4b5c-f575-a9bd692bc07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in GCA_000001405.15_GRCh38_genomic.fna: 0.150838 seconds\n",
            "Average time for 100 iterations in GCF_000001405.26_GRCh38_genomic.fna: 0.157668 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10'000"
      ],
      "metadata": {
        "id": "kDdmzu8hhYS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "\n",
        "# List the Human Genom files\n",
        "genom_files = [\n",
        "    'GCA_000001405.15_GRCh38_genomic.fna',\n",
        "    'GCF_000001405.26_GRCh38_genomic.fna'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file\n",
        "total_time_per_file = {file: 0 for file in genom_files}\n",
        "\n",
        "for genom_file in genom_files:\n",
        "    for _ in range(num_iterations):\n",
        "        # Load Genom file\n",
        "        genom_file_path = '/content/drive/MyDrive/data/' + genom_file\n",
        "        for record in iv.fasta.reader(file=genom_file_path):\n",
        "            # Consider the first 10,000 characters in the current sequence\n",
        "            reference_text_chunk = record.seq[:10000]\n",
        "\n",
        "            # Measure the time for searching in the FMIndex\n",
        "            start_time = time.time()\n",
        "            res = index.search(reference_text_chunk)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Accumulate the total time per file\n",
        "            total_time_per_file[genom_file] += end_time - start_time\n",
        "\n",
        "# Calculate the average time per file\n",
        "average_time_per_file = {file: total_time / num_iterations for file, total_time in total_time_per_file.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, average_time in average_time_per_file.items():\n",
        "    print(f\"Average time for {num_iterations} iterations in {file}: {average_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYrmoROUhbBr",
        "outputId": "1034c9d2-d8af-4d37-bc00-5fd06170abfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in GCA_000001405.15_GRCh38_genomic.fna: 0.169791 seconds\n",
            "Average time for 100 iterations in GCF_000001405.26_GRCh38_genomic.fna: 0.168487 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 100'000"
      ],
      "metadata": {
        "id": "0J5zV_87hbWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "\n",
        "# List the Human Genom files\n",
        "genom_files = [\n",
        "    'GCA_000001405.15_GRCh38_genomic.fna',\n",
        "    'GCF_000001405.26_GRCh38_genomic.fna'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file\n",
        "total_time_per_file = {file: 0 for file in genom_files}\n",
        "\n",
        "for genom_file in genom_files:\n",
        "    for _ in range(num_iterations):\n",
        "        # Load Genom file\n",
        "        genom_file_path = '/content/drive/MyDrive/data/' + genom_file\n",
        "        for record in iv.fasta.reader(file=genom_file_path):\n",
        "            # Consider the first 100,000 characters in the current sequence\n",
        "            reference_text_chunk = record.seq[:100000]\n",
        "\n",
        "            # Measure the time for searching in the FMIndex\n",
        "            start_time = time.time()\n",
        "            res = index.search(reference_text_chunk)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Accumulate the total time per file\n",
        "            total_time_per_file[genom_file] += end_time - start_time\n",
        "\n",
        "# Calculate the average time per file\n",
        "average_time_per_file = {file: total_time / num_iterations for file, total_time in total_time_per_file.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, average_time in average_time_per_file.items():\n",
        "    print(f\"Average time for {num_iterations} iterations in {file}: {average_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXEANzIvhhw1",
        "outputId": "ae207fe2-94fc-4402-dbe0-dbe45e1c7cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in GCA_000001405.15_GRCh38_genomic.fna: 0.205397 seconds\n",
            "Average time for 100 iterations in GCF_000001405.26_GRCh38_genomic.fna: 0.205804 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1'000'000"
      ],
      "metadata": {
        "id": "PCsgr_scheNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "\n",
        "# List the Human Genom files\n",
        "genom_files = [\n",
        "    'GCA_000001405.15_GRCh38_genomic.fna',\n",
        "    'GCF_000001405.26_GRCh38_genomic.fna'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file\n",
        "total_time_per_file = {file: 0 for file in genom_files}\n",
        "\n",
        "for genom_file in genom_files:\n",
        "    for _ in range(num_iterations):\n",
        "        # Load Genom file\n",
        "        genom_file_path = '/content/drive/MyDrive/data/' + genom_file\n",
        "        for record in iv.fasta.reader(file=genom_file_path):\n",
        "            # Consider the first 1,000,000 characters in the current sequence\n",
        "            reference_text_chunk = record.seq[:1000000]\n",
        "\n",
        "            # Measure the time for searching in the FMIndex\n",
        "            start_time = time.time()\n",
        "            res = index.search(reference_text_chunk)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Accumulate the total time per file\n",
        "            total_time_per_file[genom_file] += end_time - start_time\n",
        "\n",
        "# Calculate the average time per file\n",
        "average_time_per_file = {file: total_time / num_iterations for file, total_time in total_time_per_file.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, average_time in average_time_per_file.items():\n",
        "    print(f\"Average time for {num_iterations} iterations in {file}: {average_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T28lH7Qkhiuy",
        "outputId": "096b50f9-787f-44c8-d2e5-5d0505f37d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in GCA_000001405.15_GRCh38_genomic.fna: 0.302196 seconds\n",
            "Average time for 100 iterations in GCF_000001405.26_GRCh38_genomic.fna: 0.300900 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FM Index Pigeon Hole Search"
      ],
      "metadata": {
        "id": "N26ZgmQAIkkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1'000"
      ],
      "metadata": {
        "id": "S3zR0I2Mv2wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "import os\n",
        "\n",
        "def k_mismatch_search(index, query, k):\n",
        "    \"\"\"\n",
        "    Perform k-mismatch search using FMIndex.\n",
        "    \"\"\"\n",
        "    result_positions = set()\n",
        "\n",
        "    # Iterate through all possible k-mismatch substrings\n",
        "    for i in range(k + 1):\n",
        "        mismatch_positions = index.search(query)\n",
        "        mismatch_positions = [(pos, errors) for pos, errors in mismatch_positions if errors <= i]\n",
        "\n",
        "        # Add the positions to the result set\n",
        "        result_positions.update(mismatch_positions)\n",
        "\n",
        "    return list(result_positions)\n",
        "\n",
        "def hamming_distance(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculate the Hamming distance between two strings of equal length.\n",
        "    \"\"\"\n",
        "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
        "\n",
        "def verify_search_results_all(reference, query, search_results, k):\n",
        "    \"\"\"\n",
        "    Verify the accuracy of k-mismatch search results using Hamming distance for all sequences.\n",
        "    \"\"\"\n",
        "    query_length = len(query)\n",
        "\n",
        "    # Check if each position in the search results has Hamming distance within k of the query\n",
        "    for result_position, errors in search_results:\n",
        "        for i in range(len(reference)):\n",
        "            substring = reference[i][result_position:result_position + query_length]\n",
        "\n",
        "            if hamming_distance(query, substring) > k:\n",
        "                print(f\"Error: Position {result_position} does not have Hamming distance within {k} of the query for sequence {i}.\")\n",
        "\n",
        "# List the Human Genome files\n",
        "genome_files = [\n",
        "    'GCA_000001405.15_GRCh38_genomic.fna',\n",
        "    'GCF_000001405.26_GRCh38_genomic.fna'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file and k value\n",
        "total_time_per_file_k = {file: {k: 0 for k in range(3)} for file in genome_files}\n",
        "\n",
        "# Load FM-index or create if it doesn't exist\n",
        "if os.path.exists(\"genome.fmindex\"):\n",
        "    index = iv.fmindex(path=\"genome.fmindex\")\n",
        "else:\n",
        "    reference_sequences = []\n",
        "    for genome_file in genome_files:\n",
        "        genome_file_path = '/content/drive/MyDrive/data/' + genome_file\n",
        "        for record in iv.fasta.reader(file=genome_file_path):\n",
        "            reference_sequences.append(iv.normalize(record.seq))\n",
        "\n",
        "    index = iv.fmindex(reference=reference_sequences, samplingRate=16)\n",
        "    index.save(\"genome.fmindex\")\n",
        "\n",
        "# Perform k-mismatch search for k = 0, 1, 2\n",
        "for k in range(3):\n",
        "    for genome_file in genome_files:\n",
        "        for _ in range(num_iterations):\n",
        "            # Load Genome file\n",
        "            genome_file_path = '/content/drive/MyDrive/data/' + genome_file\n",
        "            for i, record in enumerate(iv.fasta.reader(file=genome_file_path)):\n",
        "                # Consider the first 1,000 characters in the current sequence\n",
        "                query_sequence = record.seq[:1000]\n",
        "\n",
        "                # Measure the time for searching in the FMIndex with k-mismatch\n",
        "                start_time = time.time()\n",
        "                search_results = k_mismatch_search(index, query_sequence, k)\n",
        "                end_time = time.time()\n",
        "\n",
        "                # Accumulate the total time per file and k value\n",
        "                total_time_per_file_k[genome_file][k] += end_time - start_time\n",
        "\n",
        "                # Verify the search results using Hamming distance for all sequences\n",
        "                verify_search_results_all(reference_sequences, query_sequence, search_results, k)\n",
        "\n",
        "# Calculate the average time per file and k value\n",
        "average_time_per_file_k = {file: {k: total_time / num_iterations for k, total_time in time_per_k.items()} for file, time_per_k in total_time_per_file_k.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, time_per_k in average_time_per_file_k.items():\n",
        "    for k, average_time in time_per_k.items():\n",
        "        print(f\"Average time for {num_iterations} iterations in {file} with k={k}: {average_time:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPDI7raWH1As",
        "outputId": "3a6e0a20-53ef-4107-fcdf-a77b51acd774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for 100 iterations in GCA_000001405.15_GRCh38_genomic.fna with k=0: 0.156519 seconds\n",
            "Average time for 100 iterations in GCA_000001405.15_GRCh38_genomic.fna with k=1: 0.158613 seconds\n",
            "Average time for 100 iterations in GCA_000001405.15_GRCh38_genomic.fna with k=2: 0.167433 seconds\n",
            "Average time for 100 iterations in GCF_000001405.26_GRCh38_genomic.fna with k=0: 0.154599 seconds\n",
            "Average time for 100 iterations in GCF_000001405.26_GRCh38_genomic.fna with k=1: 0.160970 seconds\n",
            "Average time for 100 iterations in GCF_000001405.26_GRCh38_genomic.fna with k=2: 0.160253 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import iv2py as iv\n",
        "import os\n",
        "\n",
        "def k_mismatch_search(index, query, k):\n",
        "    \"\"\"\n",
        "    Perform k-mismatch search using FMIndex.\n",
        "    \"\"\"\n",
        "    result_positions = set()\n",
        "\n",
        "    # Iterate through all possible k-mismatch substrings\n",
        "    for i in range(k + 1):\n",
        "        mismatch_positions = index.search(query)\n",
        "        mismatch_positions = [(pos, errors) for pos, errors in mismatch_positions if errors <= i]\n",
        "\n",
        "        # Add the positions to the result set\n",
        "        result_positions.update(mismatch_positions)\n",
        "\n",
        "    return list(result_positions)\n",
        "\n",
        "def hamming_distance(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculate the Hamming distance between two strings of equal length.\n",
        "    \"\"\"\n",
        "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
        "\n",
        "def verify_search_results_all(reference, query, search_results, k):\n",
        "    \"\"\"\n",
        "    Verify the accuracy of k-mismatch search results using Hamming distance for all sequences.\n",
        "    \"\"\"\n",
        "    query_length = len(query)\n",
        "\n",
        "    # Check if each position in the search results has Hamming distance within k of the query\n",
        "    for result_position, errors in search_results:\n",
        "        for i in range(len(reference)):\n",
        "            substring = reference[i][result_position:result_position + query_length]\n",
        "\n",
        "            if hamming_distance(query, substring) > k:\n",
        "              pass\n",
        "                #print(f\"Position {result_position} does not have Hamming distance within {k} of the query for sequence {i}.\")\n",
        "\n",
        "# List the Human Genome files\n",
        "genome_files = [\n",
        "    'illumina_reads_40.fasta',\n",
        "    'illumina_reads_60.fasta'\n",
        "]\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 100\n",
        "\n",
        "# Dictionary to store total time per file and k value\n",
        "total_time_per_file_k = {file: {k: 0 for k in range(3)} for file in genome_files}\n",
        "\n",
        "# Load FM-index or create if it doesn't exist\n",
        "if os.path.exists(\"genome.fmindex\"):\n",
        "    index = iv.fmindex(path=\"genome.fmindex\")\n",
        "else:\n",
        "    reference_sequences = []\n",
        "    for genome_file in genome_files:\n",
        "        genome_file_path = '/content/drive/MyDrive/data/' + genome_file\n",
        "        for record in iv.fasta.reader(file=genome_file_path):\n",
        "            reference_sequences.append(iv.normalize(record.seq))\n",
        "\n",
        "    index = iv.fmindex(reference=reference_sequences, samplingRate=16)\n",
        "    index.save(\"genome.fmindex\")\n",
        "\n",
        "# Perform k-mismatch search for k = 0, 1, 2\n",
        "for k in range(3):\n",
        "    for genome_file in genome_files:\n",
        "        for _ in range(num_iterations):\n",
        "            # Load Genome file\n",
        "            genome_file_path = '/content/drive/MyDrive/data/' + genome_file\n",
        "            for i, record in enumerate(iv.fasta.reader(file=genome_file_path)):\n",
        "                # Consider the first 1,000 characters in the current sequence\n",
        "                query_sequence = record.seq[:1000]\n",
        "\n",
        "                # Measure the time for searching in the FMIndex with k-mismatch\n",
        "                start_time = time.time()\n",
        "                search_results = k_mismatch_search(index, query_sequence, k)\n",
        "                end_time = time.time()\n",
        "\n",
        "                # Accumulate the total time per file and k value\n",
        "                total_time_per_file_k[genome_file][k] += end_time - start_time\n",
        "\n",
        "                # Verify the search results using Hamming distance for all sequences\n",
        "                verify_search_results_all(reference_sequences, query_sequence, search_results, k)\n",
        "\n",
        "# Calculate the average time per file and k value\n",
        "average_time_per_file_k = {file: {k: total_time / num_iterations for k, total_time in time_per_k.items()} for file, time_per_k in total_time_per_file_k.items()}\n",
        "\n",
        "# Print the results\n",
        "for file, time_per_k in average_time_per_file_k.items():\n",
        "    for k, average_time in time_per_k.items():\n",
        "        print(f\"Average time for {num_iterations} iterations in {file} with k={k}: {average_time:.6f} seconds\")"
      ],
      "metadata": {
        "id": "af9zgWd_XTzY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}